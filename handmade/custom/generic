#! /usr/bin/env python3

# Date:         Tue Apr 12 07:00:39 PM CDT 2022
# Description:  Given a URL download the images

''' Libreries '''
import os
import re
import sys
import base64
import requests
from bs4 import BeautifulSoup

''' Variables '''
urls = [
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtYnJhbmR5LXJlbmVlLXRpa3Rva2VyLWhlcm1vc2EtdGV0b25hLWZvdG9zLWRlLXBhZ28vCg==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtdmFsZXJpYS1iZWxlbi1pbmZsdWVuY2Vycy1jdWxvbmEtZm90b3MtZmlsdHJhZGFzLWNvbnRlbmlkby1wcml2YWRvLwo=',
    'aHR0cHM6Ly9lbHBhY2submV0L3BhY2stZGUtc2h1bmxpLW1laS15b3V0dWJlci1mb3Rvcy1zdXBlci1jYWNob25kYS1mb3Rvcy1kZS1wYWdvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L3BhY2stZGUtY2hsb2Utb2tpY2hsb2VvLWZvdG9zLXN1cGVyLWNhY2hvbmRhcy1mb3Rvcy1kZS1wYWdvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtZW1tYS13ZXNsZXktaW5mbHVlbmNlci1jdWxvbmEtaG90LWZvdG9zLWRlLXBhZ28v',
    'aHR0cHM6Ly9lbHBhY2submV0L2thcmVseS1ydWl6LWluZmx1ZW5jZXItZm90b3MtZmlsdHJhZGFzLXRldG9uYS1mb3Rvcy1kZS1wYWdvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtaGFubmFoLW93by1zdHJlYW1lci1mb3Rvcy1maWx0cmFkYXMtb2Yv',
    'aHR0cHM6Ly9lbHBhY2submV0L2hhbm5haC1vd28tc3RyZWFtZXItcGFjay1kZS1mb3Rvcy1jYWNob25kYXMteS1kZXNudWRhLWZvdG9zLWRlLXBhZ28tYWN0dWFsaXphZG8tMTAtMDItMjAyMi8=',
    'aHR0cHM6Ly9lbHBhY2submV0L3BhY2stZGUtbWFyaW5hLW11aS15b3V0dWJlci1mb3Rvcy1kZXNudWRhLWZpbHRyYWRhcy1mb3Rvcy1kZS1wYWdvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L3BhY2stZGUteGxpZ2h0bW9vbngtc3RyZWFtZXItZm90b3MtaG90LWRlLXN1LW1pcHJpdi1hY3R1YWxpemFkby0yNy0wMS0yMDIyLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUteGxpZ2h0bW9vbngtc3RyZWFtZXItZm90aXRvcy1ob3QtZGUtc3Utb2YtZm90b3MtZGUtcGFnby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtdXI0dml0eS1jb3NwbGF5ZXItZm90b3MtZmlsdHJhZGFzLWhvdC1jb250ZW5pZG8tcHJpdmFkby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L3BhY2stZGUtanVwaXRlci1idW5ueS1lZ2lybC13YWlmdS1zZXh5LXRlZW4tZm90b3MtZGUtcGFnby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtbWlhLXdhaWZ1bWlpYS1jb3NwbGF5ZXItZm90b3MtZmlsdHJhZGFzLWhvdC1jb250ZW5pZG8tcHJpdmFkby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtbGV0aWNpYS1zaGlyYXl1a2ktY29zcGxheWVyLWZvdG9zLWZpbHRyYWRhcy1jYWNob25kYS1jb250ZW5pZG8tcHJpdmFkby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtbWVsYWRpbmhhLWNvc3BsYXllci1mb3Rvcy1kZXNudWRhLWNvbnRlbmlkby1wcml2YWRvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtYXJpYS1ib29iaWUtY29zcGxheWVyLWZvdG9zLW1hcy1jYWNob25kYXMtZm90b3MtZGUtcGFnby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L21pY2gtemVwZWRhLXN0cmVhbWVyeW91dHViZXItZm90b3MtZGVzbnVkYS1maWx0cmFkYXMtZm90b3MtZGUtcGFnby1hY3R1YWxpemFkby0yMy0wMi0yMDIyLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtYXJhbnphc2ludGUteW91dHViZXIteS1zdHJlYW1lci1mb3Rvcy1maWx0cmFkYXMtZGUtc3UtbXlwcml2Lw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtYnJpZ2l0dGUtZ3JleS1zdHJlYW1lci15LWNvc3BsYXllci1mb3Rvcy1ob3QtZGUtc3UtbXlwcml2Lw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtYnJpZ2l0dGUtZ3JleS1zdHJlYW1lci15b3V0dWJlci1mb3Rvcy1ob3QtZGUtc3Utb25seWZhbnMv',
    'aHR0cHM6Ly9lbHBhY2submV0L2JlbGxlLWRlbHBoaW5lLXN0cmVhbWVyLXktY29zcGxheWVyLWRlc251ZGEteS1tYXMtY29udGVuaWRvLXByb2hpYmlkby1hY3R1YWxpemFkby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2JlbGxlLWRlbHBoaW5lLXN0cmVhbWVyLXktY29zcGxheWVyLWZvdG9zLW1hcy1jYWNob25kYXMtZGVzbnVkYS1mb3Rvcy1kZS1wYWdvLw==',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtbG93LWtleWRlYWRpbnNpZGUtZS1naXJsLXRldG9uYS1ob3QtZm90b3MtZGUtcGFnby8=',
    'aHR0cHM6Ly9lbHBhY2submV0L2VsLXBhY2stZGUtbWVsYWRpbmhhLWNvc3BsYXllci1mb3Rvcy1kZXNudWRhLWNvbnRlbmlkby1wcml2YWRvLw==',
]

# uncomment to see the names & ./generic | base64 -d
# for name in urls:
#    print(name + 'Cg==')
# sys.exit(1)

total = len(urls)

''' Functions '''
def downloader(target, outpath='downloads'):
    # get the source code
    r = requests.get(target, timeout=1)
    bs = BeautifulSoup(r.text, 'html.parser')
    # search for the images
    links = [
        img['src'].replace('thumbs', 'images').replace('t.jpg','o.jpg')
        for img in bs.find_all('img', {'alt':'image host'})
    ]
    # print(links)
    total = len(links)
    # create output folder
    os.makedirs(outpath, exist_ok=True)
    # outpath = '{}/{}'.format(outpath, target.split('/')[-2].replace('-', '').encode('utf-8').hex() )
    outpath = '{}/{}'.format(
        outpath,
        base64.b64encode(target.split('/')[-2].replace('-', '').encode('utf-8')).decode('utf-8')
    )
    os.makedirs(outpath, exist_ok=True)
    # iterate the image links
    for i, link in enumerate(links):
        # generate file name
        name = re.search("(?:\w)*\.jpg$", link).group()
        file = '{}/{}'.format(outpath, name)
        if os.path.exists(file):
            continue
        # clear screen
        # os.system('cls||clear')
        # print status
        print('\t{}/{} ({:.2f} %): {} -> {}'.format(i+1, total, (i/total)*100, link, outpath[0:10]+'...'+outpath[-5:]), end="\r", flush=True)
        # get the image bytes
        try:
            r = requests.get(link)
        except KeyboardInterrupt:
            sys.exit(0)
        except:
            continue
        with open(file, 'wb') as f:
            f.write(r.content)

''' Main '''
if __name__ == '__main__':
    for i, url in enumerate(urls):
        # clear screen
        os.system('clear')
        print('[+] Downloading {}/{}'.format(i+1, total))
        downloader(base64.b64decode(url).decode('utf-8'))
